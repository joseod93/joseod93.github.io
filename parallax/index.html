<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Three.js Head Tracking Parallax</title>
    <style>
        body { margin: 0; overflow: hidden; background-color: #1a1a1a; }
        canvas { display: block; }
        
        /* Contenedor para mostrar la webcam (opcional para debug) */
        #video-container {
            position: absolute;
            top: 10px;
            left: 10px;
            width: 160px;
            height: 120px;
            border-radius: 8px;
            overflow: hidden;
            border: 2px solid white;
            z-index: 10;
            opacity: 0.7;
        }
        
        video {
            width: 100%;
            height: 100%;
            object-fit: cover;
            transform: scaleX(-1); /* Efecto espejo */
        }

        #loading {
            position: absolute;
            top: 50%; left: 50%;
            transform: translate(-50%, -50%);
            color: white;
            font-family: sans-serif;
            font-size: 1.5rem;
            pointer-events: none;
            text-align: center;
        }
    </style>
    
    <!-- Import Maps para usar módulos ES6 directamente desde CDN -->
    <script type="importmap">
        {
            "imports": {
                "three": "https://unpkg.com/three@0.160.0/build/three.module.js",
                "three/addons/": "https://unpkg.com/three@0.160.0/examples/jsm/",
                "@mediapipe/tasks-vision": "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/+esm"
            }
        }
    </script>
</head>
<body>

    <div id="loading">Cargando IA y Cámara...<br><span style="font-size: 0.8rem">Por favor permite el acceso a la webcam</span></div>
    
    <div id="video-container">
        <video id="webcam" autoplay playsinline></video>
    </div>

    <script type="module">
        import * as THREE from 'three';
        import { FilesetResolver, FaceLandmarker } from '@mediapipe/tasks-vision';

        // --------------------------------------------------------
        // 1. CONFIGURACIÓN DE THREE.JS
        // --------------------------------------------------------
        const scene = new THREE.Scene();
        scene.fog = new THREE.FogExp2(0x1a1a1a, 0.04);

        const camera = new THREE.PerspectiveCamera(50, window.innerWidth / window.innerHeight, 0.1, 100);
        camera.position.z = 5;

        const renderer = new THREE.WebGLRenderer({ antialias: true });
        renderer.setSize(window.innerWidth, window.innerHeight);
        renderer.setPixelRatio(window.devicePixelRatio);
        document.body.appendChild(renderer.domElement);

        // --- Luces ---
        const ambientLight = new THREE.AmbientLight(0xffffff, 0.5);
        scene.add(ambientLight);
        
        const dirLight = new THREE.DirectionalLight(0xff00ff, 2);
        dirLight.position.set(5, 5, 5);
        scene.add(dirLight);

        const blueLight = new THREE.PointLight(0x00ffff, 2);
        blueLight.position.set(-5, -5, 2);
        scene.add(blueLight);

        // --- Objetos para notar el Parallax ---
        // Objeto Central
        const geometry = new THREE.IcosahedronGeometry(1, 1);
        const material = new THREE.MeshStandardMaterial({ 
            color: 0xffffff, 
            roughness: 0.1, 
            metalness: 0.8 
        });
        const mainObj = new THREE.Mesh(geometry, material);
        scene.add(mainObj);

        // Fondo de partículas (cubos flotantes) para dar profundidad
        const floatingGroup = new THREE.Group();
        const boxGeo = new THREE.BoxGeometry(0.2, 0.2, 0.2);
        const boxMat = new THREE.MeshStandardMaterial({ color: 0x444444 });

        for (let i = 0; i < 100; i++) {
            const mesh = new THREE.Mesh(boxGeo, boxMat);
            // Posicionamos aleatoriamente, algunos muy atrás, algunos cerca
            mesh.position.x = (Math.random() - 0.5) * 20;
            mesh.position.y = (Math.random() - 0.5) * 20;
            mesh.position.z = (Math.random() - 0.5) * 15 - 5; // Mayoría detrás
            mesh.rotation.set(Math.random(), Math.random(), Math.random());
            floatingGroup.add(mesh);
        }
        scene.add(floatingGroup);


        // --------------------------------------------------------
        // 2. CONFIGURACIÓN DE MEDIAPIPE (TRACKING)
        // --------------------------------------------------------
        let faceLandmarker = undefined;
        let webcamRunning = false;
        const video = document.getElementById('webcam');

        // Variables para suavizar el movimiento (Lerp)
        let targetX = 0;
        let targetY = 0;
        let currentX = 0;
        let currentY = 0;
        
        // Intensidad del efecto parallax
        const PARALLAX_AMP = 3.5; 

        // Inicializar la IA de visión
        async function createFaceLandmarker() {
            const filesetResolver = await FilesetResolver.forVisionTasks(
                "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/wasm"
            );
            faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {
                baseOptions: {
                    modelAssetPath: `https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`,
                    delegate: "GPU"
                },
                outputFaceBlendshapes: false,
                runningMode: "VIDEO",
                numFaces: 1
            });
            startWebcam();
        }

        // Iniciar Webcam
        function startWebcam() {
            navigator.mediaDevices.getUserMedia({ video: true }).then((stream) => {
                video.srcObject = stream;
                video.addEventListener("loadeddata", () => {
                    webcamRunning = true;
                    document.getElementById('loading').style.display = 'none';
                    predictWebcam();
                });
            }).catch(err => {
                console.error(err);
                document.getElementById('loading').innerText = "Error: No se pudo acceder a la cámara.";
            });
        }

        // Ciclo de predicción
        let lastVideoTime = -1;
        async function predictWebcam() {
            if (webcamRunning) {
                let startTimeMs = performance.now();
                if (video.currentTime !== lastVideoTime) {
                    lastVideoTime = video.currentTime;
                    const startTime = performance.now();
                    const faceLandmarkerResult = faceLandmarker.detectForVideo(video, startTime);
                    
                    if (faceLandmarkerResult.faceLandmarks.length > 0) {
                        // El landmark 1 es la punta de la nariz (buen punto central)
                        const nose = faceLandmarkerResult.faceLandmarks[0][1];
                        
                        // MediaPipe da coordenadas de 0 a 1.
                        // Invertimos X porque la cámara es espejo
                        // Convertimos a rango -1 a 1
                        const rawX = (1 - nose.x) * 2 - 1; 
                        const rawY = (1 - nose.y) * 2 - 1; 

                        // Asignamos el objetivo
                        targetX = rawX * PARALLAX_AMP;
                        targetY = -rawY * PARALLAX_AMP; // Invertir Y para que se sienta natural
                    }
                }
                requestAnimationFrame(predictWebcam);
            }
        }
        
        // Iniciar todo
        createFaceLandmarker();


        // --------------------------------------------------------
        // 3. RENDER LOOP Y LÓGICA DE MOVIMIENTO
        // --------------------------------------------------------
        
        function animate() {
            requestAnimationFrame(animate);

            // 1. Interpolación Lineal (Lerp) para suavizar el movimiento de la cámara
            // Esto evita que la cámara tiemble si la detección no es perfecta
            currentX += (targetX - currentX) * 0.05; // 0.05 es el factor de suavizado (menor = más suave/lento)
            currentY += (targetY - currentY) * 0.05;

            // 2. Aplicar posición a la cámara
            // Mantenemos Z fijo, movemos X e Y
            camera.position.x = currentX;
            camera.position.y = currentY;
            
            // La cámara siempre debe mirar al centro (donde está el cubo principal)
            camera.lookAt(0, 0, 0);

            // 3. Rotación o animación suave de objetos
            mainObj.rotation.y += 0.01;
            mainObj.rotation.x += 0.005;
            floatingGroup.rotation.y -= 0.002;

            renderer.render(scene, camera);
        }

        animate();

        // Responsive
        window.addEventListener('resize', () => {
            camera.aspect = window.innerWidth / window.innerHeight;
            camera.updateProjectionMatrix();
            renderer.setSize(window.innerWidth, window.innerHeight);
        });
    </script>
</body>
</html>